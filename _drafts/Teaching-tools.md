---
title: "Teaching tools"
layout: post
date: 2016-05-08
---

{% newthought 'The recent flurry of media concern' %} over the revelation that Facebook uses human curators to modify the output of their trending algorithm has raised some interesting questions about what people think it is that algorithms do, exactly.<!--more-->
There is some reasonably cogent discussion currently available online and in academic journals about the potential for bias embedded in algorithms. 
We tend to think of bias in interactive information retrieval algorithms as attributable of the huge number people using a given search engine or information source. 
Algorithms that take input from users in the form of feedback (clicks, mostly) use this data to guess as to whether the links returned in a search engine results page (SERP) are relevant to a given user. 
This sort of automated analysis aggregates over time and the algorithm learns features that it associates with elements of queries. 
The conventional logic goes like this: if a whole bunch of racist people search and click on things that match their worldview, it is possible to coerce an automated system into becoming racist. 
Famously, this happened with Google Photos automatic identification features labeled two black people as gorillas. 

But there is a different kind of bias as well, 


## Choice

In my summer class,{% sidenote 'inls161-link' '*[Tools for Information Literacy](http://inls161.johndmart.in)*' %} I aim to give students a platform through which they can develop high quality documentation &mdash; both on- and offline &mdash; and materials for presentation. 
The course also introduces students to some basic aspects of how computing and networking work, as well some basic aspects of handling data. 
It is an introductory course, and fulfills a technology requirement, but when I was given the assignment last year, I felt like it could be updated slightly to be a great deal more than it had been in the past.{% marginnote 'acknowledgements' 'I would like to point out here that my reaction to the design of the course as it stood when I inherited it is related to changes in technology over the last two decades. The course was originally taught by Barbara Wildemuth, who also taught it to SILS faculty in the early days of personal computing. Ron Bergquist, who taught the course for many years, believed as well that it was time for an update and supported my efforts heartily.' %}
Originally focusing mainly on using productivity suite tools to a high degree of skill, I saw the opportunity to connect the course to some other areas of computing that might serve fledgling information professionals interacting with technology as sometimes programmers, sometimes users. 

Instead of focusing on productivity tools, I made the decision to design the course thinking about workflow, rather than interface. 
Toolchains, or the specific series of programs and commands that would take a user from source to completion of a given task or series of tasks. 
I made a few choices about this aproach that reflect my own values related to the relative simplicity and complexity of interfaces. 
In my worldview, an interface should only be as complex as it needs to be, and no more. 
It should not obscure anything, either, meaning that I prefer interfaces that have a high degree of transparency with regard to what is going on underneath. 
I also prefer, with great zeal, to use open source software tools whenever possible. 

For this course, I decided that our workflow would stick to command-line interfaecs wherever possible and that we would begin with plaintext and work our way up to finished, formatted polished outputs that were nearly universally accessible. 
This also afforded me the opportunity to introduce version control as a part of the workflow, because plaintext can be easily tracked through tools like Git on platforms like GitHub. 

git@github.com:clayh53/tufte-jekyll.git

## Epistemology